{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./airbnb.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Recap - Where we stand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall goal\n",
    "Build a (toy) Data Science project from scratch\n",
    "\n",
    "#### Steps\n",
    "- parsing airbnb pages\n",
    "    - static - done\n",
    "    - dynamic - done\n",
    "    - [data example](https://github.com/x-technology/airbnb-analytics/blob/main/Part%201%20-%20Web%20Scraping/data_sample.csv)\n",
    "- data cleaning and preprocessing\n",
    "    - today\n",
    "- machine learning\n",
    "- building a web-extension\n",
    "- (maybe some pipelining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal for today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make clean data happen!.. With Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://res.cloudinary.com/springboard-images/image/upload/w_1080,c_limit,q_auto,f_auto,fl_lossy/wordpress/2019/08/sb-blog-data-cleaning.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a typical import\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other stuff\n",
    "import datetime\n",
    "import re\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### a. Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_rooms = '8 guests ¬∑ 3 bedrooms ¬∑ 8 beds ¬∑ 0 baths'\n",
    "var_rooms.split(' ¬∑ ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_rooms = '8 guests ¬∑ 3 bedrooms ¬∑ 8 beds ¬∑ 0 baths'\n",
    "var_rooms.replace(' ¬∑ ', '**__**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### startswith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_str = 'random_stuff'\n",
    "var_str.startswith('rand'), var_str.startswith('RAND')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### b. Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply all elements by 10\n",
    "for i in var_list:\n",
    "    print(10*i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[10*i for i in var_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### double comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_array = [\n",
    "    ['Dog', 'Cat', 'Elephant'],\n",
    "    ['table', 'chair', 'couch', 'drawer']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprehension with no actions - still nested\n",
    "[el for el in var_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double comprehension\n",
    "[sub_el for el in var_array for sub_el in el]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['a', 'a', 'b', 'c', 'e', 'e', 'x', 'x', 'x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### c. Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../airbnb-analytics/Part 1 - Web Scraping/Mayrhofen_AT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate the totals\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or the non-missing totals\n",
    "data.notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['refundables'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['refundables'].fillna('NOPE').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facilities'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facilities'].replace('Kitchen', 'Bathroom').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### handling strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['rooms', 'facilities', 'header']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rooms'].str.split(' ¬∑ ').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facilities'].str.startswith('Kitchen').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['header'].apply(str.split).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_lambda = lambda x: 2*x\n",
    "\n",
    "def func_normal(x):\n",
    "    return 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(func_lambda(4))\n",
    "print(func_normal(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### apply + lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['header'].apply(lambda x: (x, 1) if 'house' in x.split() else (x, 0)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to get a name and a family name from the corporate mail\n",
    "var_str = 'Roger.Federer111@gmail.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .* = any symbol, any amount\n",
    "re.findall(r'(.*)@(.*)', var_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [a-z]+ - at least one small letter\n",
    "- [A-Za-z0-9_] - one alpha-numeric symbol\n",
    "- ... much more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Itertools\n",
    "A Python library for looping, iterations, cross product, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "var_list = data['facilities'].str.split().str[0].to_list()\n",
    "print(var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(key, len(list(group))) for key, group in itertools.groupby(sorted(var_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Use-cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('../../airbnb-analytics/Part 1 - Web Scraping/Mayrhofen_AT.csv')\n",
    "data_2 = pd.read_csv('../../airbnb-analytics/Part 1 - Web Scraping/Kitzbuehel_AT.csv')\n",
    "data_3 = pd.read_csv('../../airbnb-analytics/Part 1 - Web Scraping/Ischgl_AT.csv')\n",
    "\n",
    "data_1['query'] = 'Mayrhofen_AT'\n",
    "data_2['query'] = 'Kitzbuehel_AT'\n",
    "data_3['query'] = 'Ischgl_AT'\n",
    "\n",
    "data = pd.concat([data_1, data_2, data_3]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['listing_ratings']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['listing_ratings'].str.split(r'\\*\\*__\\*\\*', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_columns = [\n",
    "    'rating_cleanliness', 'rating_accuracy',\n",
    "    'rating_communication', 'rating_location',\n",
    "    'rating_check-in', 'rating_value'\n",
    "]\n",
    "\n",
    "data[rating_columns] = data['listing_ratings'].str.split('\\*\\*__\\*\\*', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:5, rating_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Merging strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSS has changed\n",
    "data[['specialties_1', 'specialties_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "data[['specialties_1', 'specialties_2']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and take non missing (like COALESCE in SQL)\n",
    "data['specialties'] = data['specialties_1'].fillna(data['specialties_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "data['specialties'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['specialties_1', 'specialties_2', 'specialties']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Create vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all specialties\n",
    "data['specialties'].fillna('empty').str.split('\\*\\*__\\*\\*').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_list = data['specialties'].fillna('empty').str.split('\\*\\*__\\*\\*').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double list comprehension\n",
    "[sub_s for s in specs_list for sub_s in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values\n",
    "set([sub_s for s in specs_list for sub_s in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_uniqie = set([sub_s for s in specs_list for sub_s in s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Filter out rare/useless values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skip:  \n",
    "* superhost (separate field)\n",
    "* cancellation policy (doesn't make sense)\n",
    "* house rules (separate field)\n",
    "\n",
    "shorten:\n",
    "* free cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_specialties(sp_list):\n",
    "    if not isinstance(sp_list, list):\n",
    "        return ''\n",
    "    new_list = []\n",
    "    for sp in sp_list:\n",
    "        if 'Free cancellation' in sp:\n",
    "            new_list.append('Free cancellation')\n",
    "        elif 'is a Superhost' in sp:\n",
    "            continue\n",
    "        elif 'Cancellation policy' in sp:\n",
    "            continue\n",
    "        elif 'House rules' in sp:\n",
    "            continue\n",
    "        else:\n",
    "            new_list.append(sp)\n",
    "            \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on one row\n",
    "data['specialties'].str.split('\\*\\*__\\*\\*')[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_specialties(data['specialties'].str.split('\\*\\*__\\*\\*')[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process\n",
    "data['specialties_clean'] = data['specialties'].str.split('\\*\\*__\\*\\*').apply(lambda x: process_specialties(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['specialties_clean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. One-Hot Encoding\n",
    "- categorical (text) values are hard to use in a Machine Learning model\n",
    "- it's easier to work with numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['query']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OHE  - the easiest \"text -> number\" transformation (embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(data[['query']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we have multiple values per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specialties = data.loc[:, ['url', 'specialties_clean']]\n",
    "data_specialties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all values\n",
    "set([sub_s for s in data_specialties['specialties_clean'].to_list() for sub_s in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_values = set([sub_s for s in data_specialties['specialties_clean'].to_list() for sub_s in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual OHE\n",
    "for _s in specs_values:\n",
    "    data_specialties[f\"specialty_{_s}\"] = data_specialties['specialties_clean'].apply(lambda x: 1 if _s in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specialties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### f. Applying regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['price_per_night']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Constructing a regex\n",
    "1. There might be the first price and a \"space\" symbol:  \n",
    "__(price ){0,1}__\n",
    "2. the price is a EUR/USD symbol and at least one digit:  \n",
    "__(\\[‚Ç¨\\$\\]\\[0-9\\]+ ){0,1}__\n",
    "3. then there is always the second price  \n",
    "__(\\[‚Ç¨\\$\\]\\[0-9\\]+)__\n",
    "4. but we want to extract only the number, so we put EUR/USD symbol out of parentheses  \n",
    "__\\[‚Ç¨\\$\\](\\[0-9\\]+)__\n",
    "5. and there's \"/ night\"  \n",
    "6. finally  \n",
    "__r'(\\[‚Ç¨\\\\$\\]\\[0-9\\]\\+ ){0,1}\\[‚Ç¨\\\\$\\](\\[0-9\\]+)/ night'__  \n",
    "__r'<font color='red'>(\\[‚Ç¨\\\\$\\]\\[0-9\\]\\+ ){0,1}</font><font color='blue'>\\[‚Ç¨\\\\$\\]</font><font color='green'>(\\[0-9\\]+)</font>/ night'__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying how it works\n",
    "price_regex = r'([‚Ç¨$][0-9]+ ){0,1}[‚Ç¨$]([0-9]+)/ night'\n",
    "\n",
    "print(data.loc[0, 'price_per_night'], re.findall(price_regex, data.loc[0, 'price_per_night']))\n",
    "print(data.loc[136, 'price_per_night'], re.findall(price_regex, data.loc[136, 'price_per_night']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_per_night'].apply(lambda x: re.findall(price_regex, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_night_EUR'] = data['price_per_night'].apply(lambda x: re.findall(price_regex, x)).str[0].str[1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_night_EUR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Used methods\n",
    "1. __As is__ ‚úîÔ∏è\n",
    "    - url\n",
    "    - header\n",
    "    - location\n",
    "    - query\n",
    "2. __Split__ ‚úÇÔ∏è\n",
    "    - rooms\n",
    "    - facilities\n",
    "    - ratings\n",
    "    - reviews\n",
    "    - prices\n",
    "    - host_feats\n",
    "3. __Coalesce__ üìå\n",
    "    - [name, name_alt]\n",
    "    - [specialties_1, specialties_2]\n",
    "    - [prices_1, prices_2]\n",
    "4. __Filter and regex__ ü§è\n",
    "    - prices\n",
    "    - host_feats\n",
    "    - house rules\n",
    "5. __One Hot Encoding__ üå°Ô∏è\n",
    "    - facilities\n",
    "    - specialties\n",
    "    - languages\n",
    "    - amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Out of scope\n",
    "- duplicates\n",
    "- convertion and scales (USD <-> EUR, 9 PM <-> 21:00)\n",
    "- typos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Discussion\n",
    "- how to write clean Pandas code?\n",
    "- use SQL if possible\n",
    "- apply preprocessing while parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Look at the results\n",
    "https://github.com/x-technology/airbnb-analytics/blob/main/Part%202%20-%20Data%20Cleaning/sample_clean.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
