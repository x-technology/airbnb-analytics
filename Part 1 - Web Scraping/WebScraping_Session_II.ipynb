{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-RdQuRek3tU"
   },
   "source": [
    "# Web parsing with Python, Beautiful Soup and Selenium - Session #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7A3FR5YZk-z7"
   },
   "source": [
    "## 1. Recap the previous session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbWU5oBkngSN"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 'Requests' library\n",
    "    * to get the page\n",
    "##### 2. BeautifulSoup\n",
    "    * to find specific elements\n",
    "##### 3. Chrome DevTools\n",
    "    * to locate the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_listings(search_page):\n",
    "    answer = requests.get(search_page, timeout=5)\n",
    "    content = answer.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    listings = soup.find_all('div', '_8s3ctt')\n",
    "\n",
    "    return listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUegttKrofLv"
   },
   "outputs": [],
   "source": [
    "airbnb_url = 'https://www.airbnb.com/s/Mayrhofen--Austria/homes?tab_id=home_tab&refinement_paths%5B%5D=%2Fhomes&flexible_trip_dates%5B%5D=april&flexible_trip_dates%5B%5D=march&flexible_trip_lengths%5B%5D=weekend_trip&date_picker_type=calendar&query=Mayrhofen%2C%20Austria&place_id=ChIJbzLYLzjdd0cRDtGuTzM_vt4&checkin=2021-04-03&checkout=2021-04-10&source=structured_search_input_header&search_type=autocomplete_click'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHCP3SZlolEx"
   },
   "outputs": [],
   "source": [
    "listings = get_listings(airbnb_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ImPFUxLMolI3",
    "outputId": "6aba1663-149c-4ec1-abd9-92142ff65f23"
   },
   "outputs": [],
   "source": [
    "len(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3J90_p-olNV",
    "outputId": "e9401a32-dcda-4723-95b4-62a6cef6a6f4"
   },
   "outputs": [],
   "source": [
    "print(listings[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/max/700/1*GLNHp0QOf5qZiHa1bnaRvg.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES_SEARCH_PAGE = {\n",
    "    'url': {'tag': 'a', 'get': 'href'},\n",
    "    'name': {'tag': 'a', 'get': 'aria-label'},\n",
    "    'header': {'tag': 'div', 'class': '_b14dlit'},\n",
    "    'rooms': {'tag': 'div', 'class': '_kqh46o', 'order': 0},\n",
    "    'facilities': {'tag': 'div', 'class': '_kqh46o', 'order': 1},\n",
    "    'badge': {'tag': 'div', 'class': '_17bkx6k'},\n",
    "    'rating_n_reviews': {'tag': 'span', 'class': '_18khxk1'},\n",
    "    'price': {'tag': 'span', 'class': '_1p7iugi'},\n",
    "    'superhost': {'tag': 'div', 'class': '_ufoy4t'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_element(listing_html, params):\n",
    "    # 1. Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = listing_html.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = listing_html.find_all(params['tag'])\n",
    "\n",
    "    # 2. Extract the right element\n",
    "    tag_order = params.get('order', 0)\n",
    "    element = elements_found[tag_order]\n",
    "        \n",
    "    # 3. Get text\n",
    "    if 'get' in params:\n",
    "        output = element.get(params['get'])\n",
    "    else:\n",
    "        output = element.get_text()\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_element(listings[0], RULES_SEARCH_PAGE['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_element(listings[0], RULES_SEARCH_PAGE['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_features(soup, rules):\n",
    "    features_dict = {}\n",
    "    for feature in rules:\n",
    "        try:\n",
    "            features_dict[feature] = extract_element(soup, rules[feature])\n",
    "        except:\n",
    "            features_dict[feature] = 'empty'\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_page_features(listings[0], RULES_SEARCH_PAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pagination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/max/564/1*Q9iBSu5nniBwc8Wt2-8Ujw.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_urls(main_url, listings_per_page=20, pages_per_location=15):\n",
    "    url_list = []\n",
    "    for i in range(pages_per_location):\n",
    "        offset = listings_per_page * i\n",
    "        url_pagination = main_url + f'&items_offset={offset}'\n",
    "        url_list.append(url_pagination)\n",
    "    \n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = build_urls(airbnb_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scrape search pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_search_pages(url_list):\n",
    "    features_list = []\n",
    "    for page in url_list:\n",
    "        listings = get_listings(page)\n",
    "        for listing in listings:\n",
    "            features = extract_page_features(listing, RULES_SEARCH_PAGE)\n",
    "            features_list.append(features)\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try for one page\n",
    "base_features = process_search_pages(url_list[4:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vN85KDj2QGh3"
   },
   "source": [
    "## 2. Dynamic pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa-iBpbMQvaZ"
   },
   "source": [
    "Let's inspect a detail page and then try to extract one of the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing name: div, _xcsyj0\n",
    "detail_url = 'https://airbnb.com' + base_features[0]['url']\n",
    "\n",
    "answer = requests.get(detail_url)\n",
    "detail_soup = BeautifulSoup(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ikq1U6PRVP7",
    "outputId": "9d7ff7b1-9b5d-4fdb-93b3-d6456d6a501b"
   },
   "outputs": [],
   "source": [
    "detail_soup.find_all('div', '_xcsyj0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some JS functions inside\n",
    "detail_soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgkmSE7VQLo8"
   },
   "source": [
    "### Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pzlp9UdR7Ru"
   },
   "source": [
    "We also have to install a chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the driver\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the page\n",
    "driver.get(detail_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get html\n",
    "page_detailed = driver.page_source\n",
    "\n",
    "# close the driver\n",
    "driver.quit()\n",
    "\n",
    "# BS\n",
    "detail_soup = BeautifulSoup(page_detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wZEIUKRTMTR",
    "outputId": "a567961b-0d16-4ec2-a658-c858088e328f"
   },
   "outputs": [],
   "source": [
    "detail_soup.find_all('div', '_xcsyj0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjozKh4rQM1x"
   },
   "source": [
    "### Buttons, Loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can click the buttons\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(detail_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities button\n",
    "element = driver.find_element_by_class_name('_13e0raay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to stop the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities button\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(detail_url)\n",
    "driver.find_element_by_class_name('_13e0raay').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have to wait till it appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(detail_url)\n",
    "time.sleep(7)\n",
    "driver.find_element_by_class_name('_13e0raay').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_detailed = driver.page_source\n",
    "driver.quit()\n",
    "detail_soup_clicked = BeautifulSoup(page_detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no amenities before\n",
    "amenities = detail_soup.find_all('div', {'class': '_aujnou'})\n",
    "len(amenities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have them now\n",
    "amenities = detail_soup_clicked.find_all('div', {'class': '_aujnou'})\n",
    "len(amenities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving some time\n",
    "##### Do we need images?\n",
    "Regards to Oguz ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(detail_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clicking more buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://miro.medium.com/max/700/1*8b78NMFeRidmZDz35HTfvA.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "detail_url = 'https://www.airbnb.com/rooms/31741201?adults=4&check_in=2021-04-06&check_out=2021-04-13&federated_search_id=7941b65b-bf17-47dc-8fe0-bce247d0657e&source_impression_id=p3_1613151799_D%2BvOz7MMKLyJexNa&guests=1'\n",
    "driver.get(detail_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking for the button element\n",
    "element = driver.find_element_by_class_name('_gby1jkw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    if no error -> element is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that doesn't work (in some cases)\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Another way to click on a button - we can use Action Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try without seeing the button\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element)\n",
    "actions.click().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Element should be in a viewport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scroll manually\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(element)\n",
    "actions.click().perform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrolling with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ActionChains(driver)\n",
    "driver.execute_script(\"arguments[0].scrollIntoView(true);\", element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    I usually succeed with 4 attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally clicking\n",
    "actions.move_to_element(element)\n",
    "actions.click().perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or\n",
    "element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scraping a detail page\n",
    "### Modifying the extract function\n",
    "\n",
    "    There is an arbitrary amount of some items, e.g. house rules.\n",
    "\n",
    "    So let's just scrape them all and concatenate.\n",
    "\n",
    "    We will care about data cleaning afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next Generation :)\n",
    "def extract_element(listing_html, params):\n",
    "    # 1. Find the right tag\n",
    "    if 'class' in params:\n",
    "        elements_found = listing_html.find_all(params['tag'], params['class'])\n",
    "    else:\n",
    "        elements_found = listing_html.find_all(params['tag'])\n",
    "\n",
    "    # 2. Extract text from these tags\n",
    "    if 'get' in params:\n",
    "        element_texts = [el.get(params['get']) for el in elements_found]\n",
    "    else:\n",
    "        element_texts = [el.get_text() for el in elements_found]\n",
    "    \n",
    "    # 2. Extract the right element\n",
    "    tag_order = params.get('order', 0)\n",
    "    element = elements_found[tag_order]\n",
    "        \n",
    "    # 3. Select a particular text or concatenate all of them\n",
    "    tag_order = params.get('order', 0)\n",
    "    if tag_order == -1:\n",
    "        output = '**__**'.join(element_texts)\n",
    "    else:\n",
    "        output = element_texts[tag_order]\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cntsr-jtXJxG",
    "outputId": "c5befdae-4920-43ab-ace1-ff27c72ecaa0"
   },
   "outputs": [],
   "source": [
    "extract_element(detail_soup_clicked, {'tag': 'div', 'class': '_u827kd', 'order': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "xwmApQvrXzhh",
    "outputId": "2bc77145-3b41-4c85-953a-210e459d2976"
   },
   "outputs": [],
   "source": [
    "extract_element(detail_soup_clicked, {'tag': 'div', 'class': '_u827kd', 'order': -1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RQzqbsJQQqs"
   },
   "source": [
    "### Process amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1y8HOXYOX7gW",
    "outputId": "2a034506-dfce-483a-d2e8-f9b92f58e781"
   },
   "outputs": [],
   "source": [
    "amenities[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every amenity has a header: class=\"_1crk6cd\"\n",
    "* Within every amenity there are multiple classes \"_1dotkqq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kGI1VpFxYeDZ",
    "outputId": "df0c5e4b-3219-43f3-f802-afb2f96c3c55"
   },
   "outputs": [],
   "source": [
    "amenities[0].find('div', '_1crk6cd').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etc2Tb2RYeHB",
    "outputId": "3e3080f0-abf3-4d8d-f582-5d8905db0295"
   },
   "outputs": [],
   "source": [
    "amenities[0].find_all('div', '_1dotkqq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes there are more elements within\n",
    "[a.get_text() for a in amenities[1].find_all('div', '_1dotkqq')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9GsP1AoZBgy",
    "outputId": "70805530-f0f5-4e5c-aeb8-ea27f2a68086"
   },
   "outputs": [],
   "source": [
    "# let's not get deeper\n",
    "[a.find(text=True) for a in amenities[1].find_all('div', '_1dotkqq')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrap in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_amenities(soup):\n",
    "    amenities = soup.find_all('div', {'class': '_aujnou'})\n",
    "    \n",
    "    amenities_dict = {}\n",
    "    for amenity in amenities:\n",
    "        header = amenity.find('div', {'class': '_1crk6cd'}).get_text()\n",
    "        values = amenity.find_all('div', {'class': '_1dotkqq'})\n",
    "        values = [v.find(text=True) for v in values]\n",
    "        \n",
    "        amenities_dict['amenity_' + header] = values\n",
    "        \n",
    "    return json.dumps(amenities_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_amenities(detail_soup_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XehNKN59QTog"
   },
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES_DETAIL_PAGE = {\n",
    "    'location': {'tag': 'span', 'class': '_jfp88qr'},\n",
    "    \n",
    "    'specialties_1': {'tag': 'div', 'class': 't1bchdij', 'order': -1},\n",
    "    'specialties_2': {'tag': 'div', 'class': '_1qsawv5', 'order': -1},\n",
    "\n",
    "    'price_per_night': {'tag': 'div', 'class': '_ymq6as'},\n",
    "    \n",
    "    'refundables': {'tag': 'div', 'class': '_cexc0g', 'order': -1},\n",
    "        \n",
    "    'prices_1': {'tag': 'li', 'class': '_ryvszj', 'order': -1},\n",
    "    'prices_2': {'tag': 'li', 'class': '_adhikmk', 'order': -1},\n",
    "    \n",
    "    'listing_ratings': {'tag': 'span', 'class': '_4oybiu', 'order': -1},\n",
    "    \n",
    "    'host_joined': {'tag': 'div', 'class': '_1fg5h8r', 'order': 1},\n",
    "    'host_feats': {'tag': 'span', 'class': '_pog3hg', 'order': -1},\n",
    "    \n",
    "    'lang_responses': {'tag': 'li', 'class': '_1q2lt74', 'order': -1},\n",
    "    'house_rules': {'tag': 'div', 'class': '_u827kd', 'order': -1},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_soup_js(listing_url, waiting_time=[3, 1]):\n",
    "    \"\"\"Extracts HTML from JS pages: open, wait, click, wait, extract\"\"\"\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--blink-settings=imagesEnabled=false')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    driver.get(listing_url)\n",
    "    time.sleep(waiting_time[0])\n",
    "        \n",
    "    # looking for price details\n",
    "    price_dropdown = 0\n",
    "    try:\n",
    "        element = driver.find_element_by_class_name('_gby1jkw')\n",
    "        price_dropdown = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # if the element is present - click on it\n",
    "    if price_dropdown == 1:\n",
    "        for i in range(10): # 10 attempts to scroll to the price button\n",
    "            try:\n",
    "                actions = ActionChains(driver)\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", element);\n",
    "                actions.move_to_element_with_offset(element, 5, 5)\n",
    "                actions.click().perform()\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    try:\n",
    "        driver.find_element_by_class_name('_13e0raay').click()\n",
    "    except:\n",
    "        pass # amentities button not found\n",
    "\n",
    "    time.sleep(waiting_time[1])\n",
    "\n",
    "    detail_page = driver.page_source\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return BeautifulSoup(detail_page, features='html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape single detail page\n",
    "def process_detail_page(url):\n",
    "    soup = extract_soup_js(url, waiting_time=[3, 1])\n",
    "    \n",
    "    features_list = []\n",
    "    features = extract_page_features(soup, RULES_DETAIL_PAGE)\n",
    "    features['amenities'] = extract_amenities(soup)\n",
    "    features_list.append(features)\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Measuring time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KdyKkAvNb4G_",
    "outputId": "1528de80-a5b2-40ec-97b3-ad5fe17afc34"
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "detail_features = process_detail_page(detail_url)\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbDQsRdjZK-R"
   },
   "source": [
    "## 5. Let's parallelize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ~10 second * 300 listings = almost 1 hour\n",
    "* CPU load = 3-8%\n",
    "\n",
    "We could:\n",
    "- open multiple Chrome windows at once\n",
    "- mock clicks there and extract the elements\n",
    "\n",
    "... All in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHZPRLNhZMMZ"
   },
   "outputs": [],
   "source": [
    "# CPU intensive process -> use multiprocessing :)\r\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should find an optimal number of pools:\n",
    "- Too few - not fast enough -> slow\n",
    "- Too many - will lack resources for scraping -> missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typically we could set \"n\" to the number of cpu's\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY-ngMYHZMeS"
   },
   "source": [
    "### Experiment with pools and waiting times. Look at script time and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_urls = ['https://www.airbnb.com'+l['url'] for l in base_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listings_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the ratio of empty values\n",
    "def check_empty(features):\n",
    "    # -2 as we have 2 prices (-1) and 2 specialties (-1)\n",
    "    cnt, cnt_empty = -2, -2\n",
    "    for listing in features:\n",
    "        for key in listing[0]:\n",
    "            cnt += 1\n",
    "            if listing[0][key] == 'empty':\n",
    "                cnt_empty += 1\n",
    "    return cnt_empty/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n_pools in [4,8]:\n",
    "    t0 = time.time()\n",
    "\n",
    "    with Pool(n_pools) as pool:\n",
    "        result = pool.map(process_detail_page, listings_urls)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    print(f\"n_pool={n_pools}\\n\\ttime={round(time.time() - t0, 2)}\\n\\tempty_ratio={round(check_empty(result), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Waiting times\n",
    "Our waiting times were [3, 1]\n",
    "\n",
    "We could try to be more patient: [5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_detail_page(url):\n",
    "    soup = extract_soup_js(url, waiting_time=[5, 2])\n",
    "    \n",
    "    features_list = []\n",
    "    features = extract_page_features(soup, RULES_DETAIL_PAGE)\n",
    "    features['amenities'] = extract_amenities(soup)\n",
    "    features_list.append(features)\n",
    "\n",
    "    return features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and repeat for 8 pools only\n",
    "for n_pools in [8]:\n",
    "    t0 = time.time()\n",
    "\n",
    "    with Pool(n_pools) as pool:\n",
    "        result = pool.map(process_detail_page, listings_urls)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    print(f\"n_pool={n_pools}\\n\\ttime={round(time.time() - t0, 2)}\\n\\tempty_ratio={round(check_empty(result), 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV2nVr90FczX"
   },
   "source": [
    "##### Was there an improvement?\n",
    "* 8 cores are faster than 4, but scrape less data\n",
    "* adjusting waiting time help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk1YItMxZNxw"
   },
   "source": [
    "##### The script\n",
    "https://github.com/x-technology/airbnb-analytics/blob/main/Part%201%20-%20Web%20Scraping/airbnb_parser.py\n",
    "\n",
    "##### Some data\n",
    "https://github.com/x-technology/airbnb-analytics/blob/main/Part%201%20-%20Web%20Scraping/data_sample.csv\n",
    "\n",
    "### Issues to consider\n",
    "- missing data\n",
    "- dirty data\n",
    "- A/B tests\n",
    "- new names for classes or new page structure\n",
    "- blocking our scraper\n",
    "- ...\n",
    "\n",
    "### Next steps in a project\n",
    "To build ML models we must have clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5OTmvozZa6x"
   },
   "outputs": [],
   "source": [
    "rooms_dirty = '7 guests 路 4 bedrooms 路 4 beds 路 3 baths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnwYQoqrKj9n",
    "outputId": "1f2066cb-7c06-4b34-9b90-c2e68bbe5349"
   },
   "outputs": [],
   "source": [
    "rooms_dirty.split(' 路 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBqt-HGALiv0"
   },
   "outputs": [],
   "source": [
    "lang_responses = 'Languages: English, Deutsch**__**Response rate: 100%**__**Response time: within an hour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_responses.split('**__**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to implement:\n",
    "- clean the data\n",
    "- build features\n",
    "- think of filling the empty values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujT-A61oW_hu"
   },
   "source": [
    "___\n",
    "### All imports in one cell (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "import json\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import os"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "WebScraping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
